{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import re\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, image_path, transform=None, is_train=True):\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        for w, _, files in os.walk(image_path):\n",
    "            for f in files:\n",
    "                if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg'):\n",
    "                    self.paths.append(os.path.join(w, f))\n",
    "                    # 1是有耄耋面相，0不是耄耋\n",
    "                    self.labels.append(int(re.findall(r'\\d+', f.split('-')[-1])[0]))\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 读取图像\n",
    "        image = Image.open(self.paths[idx]).convert('RGB')\n",
    "\n",
    "        # 应用数据增强\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # 调整图像大小\n",
    "    transforms.Resize((224, 224)),\n",
    "    # 随机水平翻转\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # 随机旋转左右90度\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    # 随机调节亮度、对比度、饱和度和色相\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # 三通道标准化，来自imagenet\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "draw = False\n",
    "\n",
    "image_path = './dataset/maodie'\n",
    "\n",
    "train_dataset = CatDataset(\n",
    "    image_path=image_path,\n",
    "    transform=transforms.Compose(train_transform.transforms[:-1]) if draw else train_transform,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "val_dataset = CatDataset(\n",
    "    image_path=image_path,\n",
    "    transform=val_transform,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "if draw:\n",
    "    for images, labels in train_loader:\n",
    "        img = np.asarray(images[0])\n",
    "        plt.imshow(img.transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        break"
   ],
   "id": "c380ef3891ee9d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class Residual(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            # 第一层进来做1*1卷积，因为特征已经被降了很多\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X # res\n",
    "        return F.relu(Y)\n",
    "\n",
    "# 3通道输入，64通道输出，7*7配合3padding输入形状不变，stride为2高宽砍半\n",
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n"
   ],
   "id": "8c443952b2468d9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "b2 = resnet_block(64, 64, 2, True)\n",
    "b3 = resnet_block(64, 128, 2)\n",
    "b4 = resnet_block(128, 256, 2)\n",
    "b5 = resnet_block(256, 512, 2)\n",
    "\n",
    "res_net = nn.Sequential(b1, nn.Sequential(*b2), nn.Sequential(*b3), nn.Sequential(*b4), nn.Sequential(*b5),\n",
    "                        # 自适应卷积，前两维1*1\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 2))\n",
    "# for k, _ in res_net.state_dict().items():\n",
    "#     print(k)"
   ],
   "id": "4edb135f55493ed5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# X_ = torch.rand(size=(1, 3, 224, 224))\n",
    "#\n",
    "# # 这一步演示钩子函数\n",
    "# def size_observe_hook(module, _, output_t):\n",
    "#     print(module.__class__.__name__, 'output shape:\\t', output_t.shape)\n",
    "#\n",
    "# # 这一步将每个module都带上观察输出的函数\n",
    "# def size_observe_attach_with_weight_init(net: nn.Sequential):\n",
    "#     # 线性曾用xavier初始化权重\n",
    "#     for m in net:\n",
    "#         if isinstance(m, nn.Sequential):\n",
    "#             size_observe_attach_with_weight_init(m)\n",
    "#         elif isinstance(m, nn.Linear):\n",
    "#             # 这一步演示用xavier正则分布初始化线性层权重\n",
    "#             torch.nn.init.xavier_uniform_(m.weight)\n",
    "#             m.bias.data.fill_(0.01)\n",
    "#             m.register_forward_hook(size_observe_hook)\n",
    "#         else:\n",
    "#             m.register_forward_hook(size_observe_hook)\n",
    "#\n",
    "# size_observe_attach_with_weight_init(res_net)\n",
    "#\n",
    "# y_ = res_net(X_)\n",
    "#\n",
    "for name, module in res_net.named_modules():\n",
    "    print(name)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "id": "45e42d1839a1f17d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "from visualization.loss_graph import Animator\n",
    "\n",
    "def to_float(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().item() if x.numel() == 1 else x.detach().cpu().numpy()\n",
    "    return float(x)\n",
    "\n",
    "res_net = res_net.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(res_net.parameters(), lr=0.001)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "animator = Animator(xlabel='epoch', ylabel='loss/accuracy', legend=['train acc', 'test acc', 'loss'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    res_net.train()\n",
    "    total_loss, total_acc, count = 0, 0, 0\n",
    "    # 训练总损失、训练精度、训练经过的样本数\n",
    "    start_time = time.time()\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = res_net(X)\n",
    "\n",
    "        l = loss(y_hat, y)\n",
    "        total_loss += l\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += l.item() * X.size(0)\n",
    "        total_acc += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "        count += X.size(0)\n",
    "    train_loss = total_loss / count\n",
    "    train_acc = total_acc / count\n",
    "\n",
    "    res_net.eval()\n",
    "    test_acc, test_count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_acc += (res_net(X).argmax(dim=1) == y).sum().item()\n",
    "            test_count += X.size(0)\n",
    "    test_acc /= test_count\n",
    "\n",
    "    # 更新图像\n",
    "    animator.add(epoch + 1, (to_float(train_acc), to_float(test_acc), to_float(train_loss)))\n",
    "    print(f\"Epoch {epoch+1}: train_acc={train_acc:.3f}, test_acc={test_acc:.3f}, train_loss={train_loss:.3f}, time={time.time()-start_time:.1f}s\")\n",
    "\n",
    "\n",
    "plt.ioff()\n",
    "display(animator.fig)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "a31c86b038867a0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "draw_iterator = DataLoader(val_dataset, batch_size=1, shuffle=True) # 就拿一个，（1，224，224）\n",
    "target_layer = '4.1.conv2'\n",
    "res_net.load_state_dict(torch.load(\"res_net.pth\"))\n",
    "res_net = res_net.to(device)\n",
    "\n",
    "def inverse_transform(tensor):\n",
    "    \"\"\"\n",
    "    将标准化后的张量转换回 PIL 图像\n",
    "    :param tensor: (3, 224, 224)\n",
    "    \"\"\"\n",
    "    tensor = tensor.clone()\n",
    "\n",
    "    # 先乘以标准差，再加上均值\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)  # (3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)\n",
    "    tensor = tensor * std + mean\n",
    "    # 将张量值限制在[0,1]范围内，防止后面乘255出问题（应该也不会出问题\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "\n",
    "    tensor = tensor.permute(1, 2, 0)  #从chw转为hwc\n",
    "    numpy_image = tensor.numpy()\n",
    "\n",
    "    # 反归一化\n",
    "    numpy_image = (numpy_image * 255).astype(np.uint8)\n",
    "    return Image.fromarray(numpy_image)\n",
    "\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model: torch.nn.Module, target_layer: str):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "        # 存储梯度和这一层输出的特征图\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        # 注册hook\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == target_layer:\n",
    "                module.register_forward_hook(self._forward_hook)\n",
    "                module.register_backward_hook(self._backward_hook)\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"Couldn't find layer '{target_layer}' in the model\")\n",
    "\n",
    "    def _forward_hook(self, _, __, output):\n",
    "        self.activations = output.detach() # (1, c, h, w)\n",
    "\n",
    "    def _backward_hook(self, _, __, output):\n",
    "        # 这个output还套一个元组里\n",
    "        self.gradients = output[0].detach() # (1, c, h, w)\n",
    "\n",
    "    def generate_cam(self, input_tensor: torch.Tensor, target_class: int, upsample_size=(224, 224)):\n",
    "        predict = self.model(input_tensor)\n",
    "        one_hot = torch.zeros_like(predict)\n",
    "        # 这个onehot编码的向量放进反向传播里面去算这一类关于最后一层卷积的梯度\n",
    "        one_hot[0, target_class] = 1  # [[0, 1]]\n",
    "\n",
    "        predict.backward(gradient=one_hot)\n",
    "\n",
    "        activations = self.activations[0]\n",
    "        gradients = self.gradients[0] # (c, h, w), (512, 7, 7)\n",
    "\n",
    "        avg = gradients.mean(dim=[1, 2], keepdim=False) # (c)\n",
    "\n",
    "        cam = torch.zeros(activations.shape[1:], dtype=activations.dtype, device=device) # (h, w)\n",
    "        for k, w in enumerate(avg):\n",
    "            cam += w * activations[k]\n",
    "\n",
    "        # 说只要正提梯度\n",
    "        cam = F.relu(cam)\n",
    "\n",
    "        # 上采样到输入尺寸\n",
    "        if upsample_size is not None:\n",
    "            cam = cam.unsqueeze(0).unsqueeze(0)  # (1,1,h,w)\n",
    "            cam = F.interpolate(cam, size=upsample_size, mode='bilinear', align_corners=False)\n",
    "            # 前2维当批量和通道用\n",
    "            cam = cam[0, 0]\n",
    "\n",
    "        # 归一化到 [0,1]\n",
    "        cam -= cam.min()\n",
    "        if cam.max() != 0:\n",
    "            cam /= (cam.max() + 1e-8)\n",
    "\n",
    "        return cam.cpu().numpy()\n",
    "\n",
    "\n",
    "gradcam = GradCAM(res_net, target_layer)\n",
    "\n",
    "for X, l in draw_iterator:\n",
    "    X = X.to(device)\n",
    "    l = l.to(device)\n",
    "    pix = X[0].cpu()\n",
    "    draw_t = inverse_transform(pix)\n",
    "    cam = gradcam.generate_cam(X, 1)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(draw_t)\n",
    "    # 热力图叠上去\n",
    "    plt.imshow(cam, cmap='jet', alpha=0.4)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break\n"
   ],
   "id": "70eb7fef274f1cfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 保存模型参数\n",
    "torch.save(res_net.state_dict(), \"res_net.pth\")\n",
    "\n",
    "# 读取模型参数\n",
    "new_model = nn.Sequential(b1, nn.Sequential(*b2), nn.Sequential(*b3), nn.Sequential(*b4), nn.Sequential(*b5),\n",
    "                        # 自适应卷积，前两维1*1\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 2))\n",
    "new_model.load_state_dict(torch.load(\"res_net.pth\"))"
   ],
   "id": "b4e32663b51e137a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "ac0c3b87682d1c32",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
